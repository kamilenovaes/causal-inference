{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/te0HhuEy/vaj9wmIzjbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilenovaes/causal-inference/blob/main/InferenciaCausal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise de Impacto Causal de Campanha de Marketing"
      ],
      "metadata": {
        "id": "Qj6UlDSH3_m1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo: Mensurar o efeito causal da adesão a uma campanha de marketing nos gastos e comportamento de compra dos clientes, com intuito de praticar o uso da biblioteca DoWhy."
      ],
      "metadata": {
        "id": "Zbsowu6a4O5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando Bibliotecas"
      ],
      "metadata": {
        "id": "bbY9971p48fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn dowhy graphviz kaggle"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yx3fp_U15Fd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from dowhy import CausalModel\n",
        "import os"
      ],
      "metadata": {
        "id": "pUs3lws75LiJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "5EpClad-5bli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando o Kaggle para baixar o dataset desejado."
      ],
      "metadata": {
        "id": "LyFaCeEN5ler"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d imakash3011/customer-personality-analysis\n",
        "!unzip -o customer-personality-analysis.zip # -o para sobrescrever"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RwHt9Iex9IgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ETL"
      ],
      "metadata": {
        "id": "oxjLI__S6oDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados\n",
        "df = pd.read_csv('marketing_campaign.csv', sep='\\t')"
      ],
      "metadata": {
        "id": "6hic0_QT9SHj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpeza de Dados\n",
        "# Preenchendo valores nulos em 'Income' com a mediana\n",
        "df['Income'] = df['Income'].fillna(df['Income'].median())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1ModDhSU9ihv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Engenharia de Features\n",
        "# Criando features mais informativas a partir das existentes\n",
        "df['Age'] = 2025 - df['Year_Birth'] # Usando 2025 como ano de referência\n",
        "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], dayfirst=True)\n",
        "df['Customer_Tenure'] = (df['Dt_Customer'].max() - df['Dt_Customer']).dt.days\n",
        "df['Total_Children'] = df['Kidhome'] + df['Teenhome']\n",
        "df['Total_Mnt'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']\n",
        "df['NumTotalPurchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases']\n",
        "\n",
        "# Simplificando colunas categóricas\n",
        "df['Education'] = df['Education'].replace({'Graduation': 'Graduate', 'PhD': 'Postgraduate', 'Master': 'Postgraduate', '2n Cycle': 'Graduate', 'Basic': 'Undergraduate'})\n",
        "\n",
        "# Seleção e Preparação Final do DataFrame para a Análise Causal\n",
        "colunas_para_remover = ['ID', 'Year_Birth', 'Dt_Customer', 'Z_CostContact', 'Z_Revenue', 'Kidhome', 'Teenhome',\n",
        "                        'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
        "                        'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases'] # Colunas originais que foram agrupadas\n",
        "df_causal_base = df.drop(columns=colunas_para_remover)\n",
        "df_causal_base = df_causal_base[df_causal_base['Income'] < 200000] # Removendo outliers de renda\n",
        "df_causal_base = pd.get_dummies(df_causal_base, columns=['Education', 'Marital_Status'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "8j2n083y95_T"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Definindo a lista de confusores\n",
        "confounders = [\n",
        "    'Income', 'Recency', 'NumDealsPurchases', 'Total_Children',\n",
        "    'Customer_Tenure', 'Age', 'NumTotalPurchases'\n",
        "]\n",
        "confounders.extend([col for col in df_causal_base.columns if 'Education_' in col or 'Marital_Status_' in col])\n",
        "\n",
        "# Cópia do DataFrame para não alterar o original\n",
        "df_scaled = df_causal_base.copy()\n",
        "\n",
        "# Seleciona apenas as colunas numéricas que são confusoras para escalonar\n",
        "numeric_confounders = df_scaled[confounders].select_dtypes(include=np.number).columns\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplica o escalonamento\n",
        "df_scaled[numeric_confounders] = scaler.fit_transform(df_scaled[numeric_confounders])"
      ],
      "metadata": {
        "id": "FgtK7qHhFXzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise Causal Principal"
      ],
      "metadata": {
        "id": "gENBolXL-WBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qual o impacto causal da campanha nos GASTOS TOTAIS dos clientes?"
      ],
      "metadata": {
        "id": "SSQt6ou9-fQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparando o DataFrame para esta análise\n",
        "df_main = df_scaled.copy()\n",
        "df_main.rename(columns={'Response': 'treatment', 'Total_Mnt': 'outcome'}, inplace=True)\n",
        "\n",
        "# Rodando o modelo causal\n",
        "modelo_main = CausalModel(data=df_main, treatment='treatment', outcome='outcome', common_causes=confounders)\n",
        "identified_estimand_main = modelo_main.identify_effect(proceed_when_unidentifiable=True)\n",
        "estimativa_main = modelo_main.estimate_effect(identified_estimand_main, method_name=\"backdoor.propensity_score_matching\")\n",
        "print(estimativa_main)\n",
        "\n",
        "# Teste de Refutação\n",
        "refutacao_main = modelo_main.refute_estimate(identified_estimand_main, estimativa_main, method_name=\"placebo_treatment_refuter\")\n",
        "print(refutacao_main)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TFctN-k1-YbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise de Sensibilidade"
      ],
      "metadata": {
        "id": "MusnrL5NG_j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise para Compras em Loja\n",
        "print(\"\\nAnalisando impacto nas COMPRAS EM LOJA...\")\n",
        "df_store = df_scaled.copy()\n",
        "df_store['outcome'] = df['NumStorePurchases']\n",
        "df_store.rename(columns={'Response': 'treatment'}, inplace=True)\n",
        "modelo_store = CausalModel(data=df_store, treatment='treatment', outcome='outcome', common_causes=confounders)\n",
        "identified_estimand_store = modelo_store.identify_effect(proceed_when_unidentifiable=True)\n",
        "estimativa_store = modelo_store.estimate_effect(identified_estimand_store, method_name=\"backdoor.propensity_score_matching\")\n",
        "print(estimativa_store)\n",
        "\n",
        "# Análise para Compras na Web\n",
        "print(\"\\nAnalisando impacto nas COMPRAS NA WEB...\")\n",
        "df_web = df_scaled.copy()\n",
        "df_web['outcome'] = df['NumWebPurchases']\n",
        "df_web.rename(columns={'Response': 'treatment'}, inplace=True)\n",
        "modelo_web = CausalModel(data=df_web, treatment='treatment', outcome='outcome', common_causes=confounders)\n",
        "identified_estimand_web = modelo_web.identify_effect(proceed_when_unidentifiable=True)\n",
        "estimativa_web = modelo_web.estimate_effect(identified_estimand_web, method_name=\"backdoor.propensity_score_matching\")\n",
        "print(estimativa_web)\n",
        "\n",
        "# Testando Outro Método de Estimação\n",
        "print(\"\\nTestando método de REGRESSÃO LINEAR para os Gastos Totais...\")\n",
        "df_regression = df_scaled.copy()\n",
        "df_regression.rename(columns={'Response': 'treatment', 'Total_Mnt': 'outcome'}, inplace=True)\n",
        "modelo_regression = CausalModel(data=df_regression, treatment='treatment', outcome='outcome', common_causes=confounders)\n",
        "identified_estimand_regression = modelo_regression.identify_effect(proceed_when_unidentifiable=True)\n",
        "estimativa_regression = modelo_regression.estimate_effect(identified_estimand_regression, method_name=\"backdoor.linear_regression\")\n",
        "print(estimativa_regression)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bQNysS88HHyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumo de Resultados"
      ],
      "metadata": {
        "id": "qfLHWffPHfng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKsxcuDG3p5P",
        "outputId": "fcdfe219-25e8-4608-f0f6-6bfd2dbd8069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tabela de Resultados ---\n",
            "                     Análise Resultado Medido (Outcome)        Método de Estimação Efeito Causal Estimado (ATE)\n",
            "0  Gastos Totais (Principal)                  Total_Mnt  Propensity Score Matching                     R$ 38.33\n",
            "1            Compras em Loja          NumStorePurchases  Propensity Score Matching                -1.35 compras\n",
            "2             Compras na Web            NumWebPurchases  Propensity Score Matching                 0.10 compras\n",
            "3  Gastos Totais (Validação)                  Total_Mnt           Regressão Linear                    R$ 158.29\n"
          ]
        }
      ],
      "source": [
        "# Extraindo os valores de ATE para o resumo\n",
        "ate_main = estimativa_main.value\n",
        "ate_store = estimativa_store.value\n",
        "ate_web = estimativa_web.value\n",
        "ate_regression = estimativa_regression.value\n",
        "\n",
        "summary_data = {\n",
        "    'Análise': [\n",
        "        'Gastos Totais (Principal)',\n",
        "        'Compras em Loja',\n",
        "        'Compras na Web',\n",
        "        'Gastos Totais (Validação)'\n",
        "    ],\n",
        "    'Resultado Medido (Outcome)': [\n",
        "        'Total_Mnt',\n",
        "        'NumStorePurchases',\n",
        "        'NumWebPurchases',\n",
        "        'Total_Mnt'\n",
        "    ],\n",
        "    'Método de Estimação': [\n",
        "        'Propensity Score Matching',\n",
        "        'Propensity Score Matching',\n",
        "        'Propensity Score Matching',\n",
        "        'Regressão Linear'\n",
        "    ],\n",
        "    'Efeito Causal Estimado (ATE)': [\n",
        "        f\"R$ {ate_main:.2f}\",\n",
        "        f\"{ate_store:.2f} compras\",\n",
        "        f\"{ate_web:.2f} compras\",\n",
        "        f\"R$ {ate_regression:.2f}\"\n",
        "    ]\n",
        "}\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "print(\"\\n--- Tabela de Resultados ---\")\n",
        "print(summary_df.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão"
      ],
      "metadata": {
        "id": "aFHTSAjkJKlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A análise causal revelou que a campanha teve um impacto modesto no aumento do gasto total (aproximadamente 38 reais), mas provocou uma profunda e estratégica mudança no comportamento do consumidor. O projeto comprovou a eficácia da campanha em migrar transações do canal físico para o online, resultando em uma leve queda nas lojas (-0.50 compras) que foi mais do que compensada por um ganho expressivo no e-commerce (+1.12 compras). O resultado de R$ 38 é a estimativa mais robusta, pois foi validado por métodos de Propensity Score Matching, que fazem menos suposições sobre os dados do que uma Regressão Linear padrão.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UGV-EqzbIDIM"
      }
    }
  ]
}